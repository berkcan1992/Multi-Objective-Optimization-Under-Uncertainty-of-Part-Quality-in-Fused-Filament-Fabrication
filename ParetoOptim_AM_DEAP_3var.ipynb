{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#    This file is part of DEAP.\n",
    "#\n",
    "#    DEAP is free software: you can redistribute it and/or modify\n",
    "#    it under the terms of the GNU Lesser General Public License as\n",
    "#    published by the Free Software Foundation, either version 3 of\n",
    "#    the License, or (at your option) any later version.\n",
    "#\n",
    "#    DEAP is distributed in the hope that it will be useful,\n",
    "#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n",
    "#    GNU Lesser General Public License for more details.\n",
    "#\n",
    "#    You should have received a copy of the GNU Lesser General Public\n",
    "#    License along with DEAP. If not, see <http://www.gnu.org/licenses/>.\n",
    "\n",
    "import array\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# imports for the BNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "\n",
    "from deap import algorithms, base, benchmarks, creator, tools\n",
    "\n",
    "IND_SIZE = 3\n",
    "N_CYCLES = 1\n",
    "BOUND_LOW, BOUND_UP = [217, 26, 1], [278, 44, 3]\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(1.0, -1.0))\n",
    "creator.create(\"Individual\", array.array, typecode='d', fitness=creator.FitnessMin, n=IND_SIZE)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Attribute generator\n",
    "toolbox.register(\"attr_temperature\", random.randint, 217, 278)\n",
    "toolbox.register(\"attr_speed\", random.randint, 26, 44)\n",
    "toolbox.register(\"attr_layer\", random.randint, 1, 3)\n",
    "\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_temperature,toolbox.attr_speed,toolbox.attr_layer), n=N_CYCLES)\n",
    "\n",
    "\n",
    "# Structure initializers\n",
    "# toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, 3)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "\n",
    "# load min and max values of the data to denormalize prediction data\n",
    "with open('maxmin.pickle', 'rb') as f:\n",
    "    [max_x, min_x, max_y, min_y] = pickle.load(f)\n",
    "\n",
    "def normalize_max_min(data, data_max, data_min):\n",
    "    return (data-data_min) / (data_max-data_min)\n",
    "\n",
    "def denormalize_max_min(data, data_max, data_min):\n",
    "    return data * (data_max-data_min) + data_min\n",
    "\n",
    "class MC_Dropout_Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_units, drop_prob):\n",
    "        super(MC_Dropout_Model, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        # network with two hidden and one output layer\n",
    "        self.layer1 = nn.Linear(input_dim, num_units)\n",
    "        self.layer2 = nn.Linear(num_units, num_units)\n",
    "        self.layer3 = nn.Linear(num_units, 2 * output_dim)\n",
    "\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = F.dropout(x, p=self.drop_prob, training=True)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = self.activation(x)\n",
    "        x = F.dropout(x, p=self.drop_prob, training=True)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# load BL model BNN\n",
    "toolbox.model = torch.load('BNN_BLmodel.pt')\n",
    "\n",
    "def evaluate(vars):\n",
    "\n",
    "    # for ii, item in enumerate(vars):\n",
    "    #     vars[ii] = denormalize_max_min(vars[ii], max_x[ii], min_x[ii])\n",
    "\n",
    "#     # load BL model BNN\n",
    "#     BL_model = torch.load('BNN_BLmodel.pt')\n",
    "\n",
    "    max_part_height = 4.2   # maximum part height mm\n",
    "\n",
    "    # print(vars[2])\n",
    "\n",
    "    # number of total layers = (maximum part height)/(height of a layer), i.e., 4.2 / (layer height)\n",
    "    if vars[2] == 1:\n",
    "        height = 0.42\n",
    "    elif vars[2] == 2:\n",
    "        height = 0.6\n",
    "    elif vars[2] == 3:\n",
    "        height = 0.7\n",
    "\n",
    "    # print(vars)\n",
    "    num_layers = np.int(max_part_height / height); # number of layers\n",
    "\n",
    "    num_interfaces = 14     # number of interfaces per layer\n",
    "    width = 0.8             # filament width in mm\n",
    "\n",
    "    inp = [] # input to BNN to make predictions\n",
    "    ycoord = 0.5 * height  # 0.5*height of a layer in mm\n",
    "    iki_y = ycoord * 2\n",
    "\n",
    "    # store inputs for GP(model disrepancy at each interface)\n",
    "    for jj in range(1, num_layers + 1):\n",
    "        for ii in range(1, num_interfaces + 1):\n",
    "            # use x & y coordinates of vertical bonds as training data for the GP\n",
    "            # Inp =[ Temperature, speed, height, x, y ]\n",
    "            inp.append([vars[0], vars[1], height, ii * width, ycoord + (jj - 1) * iki_y])\n",
    "\n",
    "    # Convert built Python lists to a Numpy array.\n",
    "    inp = np.array(inp, dtype='float32')\n",
    "\n",
    "    # normalize data\n",
    "    inp = normalize_max_min(inp, max_x, min_x)\n",
    "\n",
    "    x_pred = torch.tensor(inp)  # convert to torch tensor\n",
    "\n",
    "    samples = []\n",
    "    noises = []\n",
    "    for i in range(10):\n",
    "        preds = toolbox.model.forward(x_pred).cpu().data.numpy()\n",
    "        samples.append(denormalize_max_min(preds[:, 0], max_y, min_y))\n",
    "        noises.append(denormalize_max_min(np.exp(preds[:, 1]), max_y, min_y))\n",
    "\n",
    "    samples, noises = np.array(samples),  np.array(noises)\n",
    "    means = (samples.mean(axis=0)).reshape(-1)\n",
    "\n",
    "    aleatoric = (noises ** 2).mean(axis=0) ** 0.5\n",
    "    epistemic = (samples.var(axis=0) ** 0.5).reshape(-1)\n",
    "    total_unc = (aleatoric ** 2 + epistemic ** 2) ** 0.5\n",
    "\n",
    "#     print(means.mean(), total_unc.mean(), vars)\n",
    "    # if means.mean()>0.7:\n",
    "    #     print(means.mean(),total_unc.mean(),vars)\n",
    "\n",
    "    # Dimensionless BL: non-dimensionalize the BL by dividing with the layer height\n",
    "    dimensionless_mean_bl = means.mean()/height\n",
    "    dimensionless_total_unc_bl = total_unc.mean()/height**2\n",
    "\n",
    "    return dimensionless_mean_bl, dimensionless_total_unc_bl\n",
    "\n",
    "\n",
    "def checkBounds(min, max):\n",
    "    def decorator(func):\n",
    "        def wrappper(*args, **kargs):\n",
    "            offspring = func(*args, **kargs)\n",
    "            for child in offspring:\n",
    "                for i in range(len(child)):\n",
    "                    if child[i] > max[i]:\n",
    "#                         print(child[i])\n",
    "                        child[i] = max[i]\n",
    "                    elif child[i] < min[i]:\n",
    "#                         print(child[i])\n",
    "                        child[i] = min[i]\n",
    "            return offspring\n",
    "        return wrappper\n",
    "    return decorator\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "# toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=BOUND_LOW, up=BOUND_UP, eta=10.0)\n",
    "# toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=BOUND_LOW, up=BOUND_UP, eta=10.0, indpb=1.0/NDIM)\n",
    "\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxUniform, indpb=0.50)\n",
    "toolbox.register(\"mutate\", tools.mutUniformInt, low=BOUND_LOW, up=BOUND_UP, indpb=0.50)\n",
    "\n",
    "\n",
    "# toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "# toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "\n",
    "# toolbox.register(\"mate\", tools.cxBlend, alpha=1.5)\n",
    "# toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=3, indpb=0.3)\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "# ref_points = tools.uniform_reference_points(nobj=2, p=12)\n",
    "# toolbox.register(\"select\", tools.selNSGA3WithMemory(ref_points))\n",
    "\n",
    "# Bounds on the design variables\n",
    "toolbox.decorate(\"mate\", checkBounds([217, 26, 1], [278, 44, 3]))\n",
    "toolbox.decorate(\"mutate\", checkBounds([217, 26, 1], [278, 44, 3]))\n",
    "\n",
    "\n",
    "def main():\n",
    "    random.seed(64)\n",
    "\n",
    "    MU, LAMBDA = 50, 50\n",
    "    pop = toolbox.population(n=MU)\n",
    "    hof = tools.ParetoFront()\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean, axis=0)\n",
    "    stats.register(\"std\", np.std, axis=0)\n",
    "    stats.register(\"min\", np.min, axis=0)\n",
    "    stats.register(\"max\", np.max, axis=0)\n",
    "\n",
    "    # CXPB  is the probability with which two individuals\n",
    "    #       are crossed\n",
    "    #\n",
    "    # MUTPB is the probability for mutating an individual\n",
    "    algorithms.eaMuPlusLambda(pop, toolbox, mu=MU, lambda_=LAMBDA,\n",
    "                              cxpb=0.7, mutpb=0.3, ngen=2,\n",
    "                              stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    return pop, stats, hof\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pop, stats, hof = main()\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy\n",
    "\n",
    "    front = numpy.array([ind.fitness.values for ind in pop])\n",
    "    plt.scatter(front[:,0], front[:,1], c=\"b\")\n",
    "    plt.axis(\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
