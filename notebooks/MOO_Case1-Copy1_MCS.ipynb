{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\anaconda3\\envs\\deep-learning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\anaconda3\\envs\\deep-learning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\anaconda3\\envs\\deep-learning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\anaconda3\\envs\\deep-learning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\anaconda3\\envs\\deep-learning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\anaconda3\\envs\\deep-learning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#    This file is part of Multi-objective optimization under uncertainty research\n",
    "\n",
    "import array, copy, random\n",
    "# import logging\n",
    "# import random\n",
    "import numpy as np\n",
    "\n",
    "# imports for the BNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle\n",
    "\n",
    "from deap import algorithms, base, creator, tools\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# set GPU device to device_num\n",
    "# device_num = 1\n",
    "# torch.cuda.set_device(device_num)\n",
    "# print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\deep-learning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\deep-learning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\deep-learning\\lib\\site-packages\\torch\\serialization.py:419: UserWarning: Couldn't retrieve source code for container of type MC_Dropout_Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n",
      "C:\\anaconda3\\envs\\deep-learning\\lib\\site-packages\\torch\\serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\anaconda3\\envs\\deep-learning\\lib\\site-packages\\torch\\serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# load min and max values of the data to denormalize prediction data\n",
    "with open('maxmin.pickle', 'rb') as f:\n",
    "    [max_x, min_x, max_y, min_y] = pickle.load(f)\n",
    "    \n",
    "# load min and max values of the data to denormalize prediction data\n",
    "with open('maxmin_thickness.pickle', 'rb') as f:\n",
    "    [X_max, X_min, Y_max, Y_min] = pickle.load(f)    \n",
    "\n",
    "def normalize_max_min(data, data_max, data_min):\n",
    "    return (data-data_min) / (data_max-data_min)\n",
    "\n",
    "def denormalize_max_min(data, data_max, data_min):\n",
    "    return data * (data_max-data_min) + data_min\n",
    "\n",
    "class KerasDropoutPrediction(object):\n",
    "    def __init__(self,model):\n",
    "        self.f = K.function(\n",
    "                [model.layers[0].input, \n",
    "                 K.learning_phase()],\n",
    "                [model.layers[-1].output])\n",
    "        \n",
    "    def predict(self, x, n_iter=10):\n",
    "        result = []\n",
    "        for _ in range(n_iter):\n",
    "            result.append(self.f([x, 1]))\n",
    "        result = np.array(result).reshape(n_iter,len(x)).T\n",
    "        return result\n",
    "    \n",
    "class MC_Dropout_Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_units, drop_prob):\n",
    "        super(MC_Dropout_Model, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        # network with two hidden and one output layer\n",
    "        self.layer1 = nn.Linear(input_dim, num_units)\n",
    "        self.layer2 = nn.Linear(num_units, num_units)\n",
    "        self.layer3 = nn.Linear(num_units, 2 * output_dim)\n",
    "\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = F.dropout(x, p=self.drop_prob, training=True)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = self.activation(x)\n",
    "        x = F.dropout(x, p=self.drop_prob, training=True)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "    \n",
    "# load BL model BNN and evaluate objectives\n",
    "model_BL = torch.load('BNN_BLmodel.pt')\n",
    "\n",
    "# load the thickness model\n",
    "model_thickness = keras.models.load_model('MCdropout_model_thickness.h5', compile=False)\n",
    "\n",
    "# predict with dropout\n",
    "kdp = KerasDropoutPrediction(model_thickness)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(vars):\n",
    "\n",
    "    # Minimize(abs(pred_mean â€“ target))\n",
    "    target  = 4.2 # desired part thickness in mm\n",
    "#     print(vars[2])\n",
    "    # number of total layers = (maximum part height)/(height of a layer), i.e., 4.2 / (layer height)\n",
    "    if vars[2] <= 1:\n",
    "        lh = 0.42\n",
    "    elif vars[2] <= 2:\n",
    "        lh = 0.6\n",
    "    elif vars[2] <= 3:\n",
    "        lh = 0.7\n",
    "\n",
    "        \n",
    "        \n",
    "    #  MODEL BOND LENGTH  \n",
    "    # print(vars)\n",
    "    num_layers = np.int(target / lh); # number of layers\n",
    "\n",
    "    num_interfaces = 14     # number of interfaces per layer\n",
    "    width = 0.8             # filament width in mm\n",
    "\n",
    "    ycoord = 0.5 * lh  # 0.5*height of a layer in mm\n",
    "    iki_y = ycoord * 2\n",
    "    \n",
    "    # Create an input array to predict overall part thickness\n",
    "    inp_BL = [] # input to BNN to make predictions\n",
    "    \n",
    "    # store inputs for GP(model disrepancy at each interface)\n",
    "    for jj in range(1, num_layers + 1):\n",
    "        for ii in range(1, num_interfaces + 1):\n",
    "            # use x & y coordinates of vertical bonds as training data for the GP\n",
    "            # Inp =[ Temperature, speed, height, x, y ]\n",
    "            inp_BL.append([vars[0], vars[1], lh, ii * width, ycoord + (jj - 1) * iki_y])\n",
    "\n",
    "    # Convert built Python lists to a Numpy array.\n",
    "    inp_BL = np.array(inp_BL, dtype='float32')\n",
    "\n",
    "    # normalize data\n",
    "    inp_BL = normalize_max_min(inp_BL, max_x, min_x)\n",
    "\n",
    "    x_pred = torch.tensor(inp_BL)  # convert to torch tensor\n",
    "\n",
    "    samples = []\n",
    "    noises = []\n",
    "    for i in range(50):\n",
    "        preds = model_BL.forward(x_pred).cpu().data.numpy()\n",
    "        samples.append(denormalize_max_min(preds[:, 0], max_y, min_y))\n",
    "        noises.append(denormalize_max_min(np.exp(preds[:, 1]), max_y, min_y))\n",
    "\n",
    "    samples, noises = np.array(samples),  np.array(noises)\n",
    "    means = (samples.mean(axis=0)).reshape(-1)\n",
    "\n",
    "    aleatoric = (noises ** 2).mean(axis=0) ** 0.5\n",
    "    epistemic = (samples.var(axis=0) ** 0.5).reshape(-1)\n",
    "    total_unc = (aleatoric ** 2 + epistemic ** 2) ** 0.5\n",
    "\n",
    "\n",
    "    # Dimensionless BL: non-dimensionalize the BL by dividing with the layer height\n",
    "    dimensionless_mean_bl = means.mean()/lh\n",
    "    dimensionless_total_unc_bl = total_unc.mean()/lh\n",
    "\n",
    "\n",
    "\n",
    "#     # MODEL THICKNESS\n",
    "#     x_pos = 7 # mm\n",
    "#     num_iter = (10.5-1.5)/0.01 + 1\n",
    "        \n",
    "#      # Create an input array to predict overall part thickness\n",
    "#     inp_thickness = []\n",
    "    \n",
    "#     # store inputs for GP(model disrepancy at each interface)\n",
    "#     for jj in range(5):\n",
    "#         y_pos = 1.5 # mm\n",
    "#         for ii in range(int(num_iter)):\n",
    "#             # use x & y coordinates of vertical bonds as training data for the GP\n",
    "#             # Inp =[ Temperature, speed, height, x, y]\n",
    "#             inp_thickness.append([vars[0], vars[1], height, x_pos, y_pos])\n",
    "#             y_pos += 0.01 # increment y position 0.01 mm\n",
    "#         x_pos += 5 # x coordinate  \n",
    "    \n",
    "#     # Convert built Python lists to a Numpy array.\n",
    "#     inp_thickness = np.array(inp_thickness, dtype='float32')\n",
    "\n",
    "#     # normalize data\n",
    "#     inp_thickness = normalize_max_min(inp_thickness, X_max, X_min)\n",
    "    \n",
    "#     # Predict\n",
    "#     y_pred_do = kdp.predict(inp_thickness,n_iter=50)\n",
    "#     y_pred_do_org = denormalize_max_min(y_pred_do, Y_max, Y_min)\n",
    "#     y_pred_do_org_mean = y_pred_do_org.mean(axis=1).reshape(-1, 1)\n",
    "#     y_pred_do_org_std = y_pred_do_org.std(axis=1).reshape(-1, 1)\n",
    "    \n",
    "#     # Predicted mean and std part thicknesses\n",
    "#     mean_part_thickness = y_pred_do_org_mean.mean()\n",
    "#     std_part_thickness = ((y_pred_do_org_std**2).mean())**0.5\n",
    "    \n",
    "    \n",
    "    return 1-dimensionless_mean_bl, dimensionless_total_unc_bl # model bond length\n",
    "#     return abs(mean_part_thickness-target), std_part_thickness # model thickness\n",
    "#     return 1-dimensionless_mean_bl, abs(mean_part_thickness-target) # model BL and thickness\n",
    "#     return 1-dimensionless_mean_bl, dimensionless_total_unc_bl, abs(mean_part_thickness-target), std_part_thickness # 4 objectives\n",
    "\n",
    "\n",
    "# lh = 0.42\n",
    "# The constraint is:\n",
    "# (Nozzle velocity) x (line width) x (layer thickness)  less than/ equal to 24 mm/s3\n",
    "def feasible(individual):\n",
    "    \"\"\"Feasability function for the individual. Returns True if feasible False\n",
    "    otherwise.\"\"\"\n",
    "#     global lh\n",
    "    \n",
    "    line_width = 0.8 # in mm\n",
    "    \n",
    "    # layer height in mm\n",
    "#     if individual[2] == 1:\n",
    "# #         height = 0.42\n",
    "#     if individual[2] > 1:\n",
    "#         height = 0.6\n",
    "#     elif individual[2] > 2:\n",
    "#         height = 0.7\n",
    "        \n",
    "    if individual[2] <= 1:\n",
    "        l_h = 0.42\n",
    "    elif individual[2] <= 2:\n",
    "        l_h = 0.6\n",
    "    elif individual[2] <= 3:\n",
    "        l_h = 0.7    \n",
    "   \n",
    "    if individual[1] * line_width * l_h <= 24:\n",
    "#         print(individual,'true')\n",
    "        return True\n",
    "#     print(individual,'false')\n",
    "    return False\n",
    "\n",
    "IND_SIZE = 3\n",
    "N_CYCLES = 1\n",
    "BOUND_LOW, BOUND_UP = [217, 26, 0], [278, 44, 3]\n",
    "\n",
    "# creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0,-1.0,-1.0)) # 4 objectives\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0)) # 2 objectives\n",
    "creator.create(\"Individual\", array.array, typecode='d', fitness=creator.FitnessMin, n=IND_SIZE)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Attribute generator\n",
    "toolbox.register(\"attr_temperature\", random.uniform, 217, 278)\n",
    "toolbox.register(\"attr_speed\", random.uniform, 26, 44)\n",
    "toolbox.register(\"attr_layer\", random.randint, 0, 3)\n",
    "\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_temperature,toolbox.attr_speed,toolbox.attr_layer), n=N_CYCLES)\n",
    "\n",
    "# Structure initializers\n",
    "# toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, 3)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "\n",
    "# A penality function can be added to any evaluation function using the DeltaPenality decorator provided in the tools module.\n",
    "# Delta = [0,1] worst cases if maximize obj1 and min. obj2\n",
    "# toolbox.decorate(\"evaluate\", tools.DeltaPenality(feasible, [0,1]))\n",
    "# Delta = [1,1] worst cases if min. obj1 and min. obj2\n",
    "toolbox.decorate(\"evaluate\", tools.DeltaPenality(feasible, [1,1])) # 2 objectives\n",
    "# toolbox.decorate(\"evaluate\", tools.DeltaPenality(feasible, [1,1,1,1])) # 4 obj\n",
    "\n",
    "\n",
    "# toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "# toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=BOUND_LOW, up=BOUND_UP, eta=100.0)\n",
    "toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=BOUND_LOW, up=BOUND_UP, eta=100.0, indpb=1.0/IND_SIZE)\n",
    "\n",
    "# toolbox.register(\"mate\", tools.cxBlend, alpha=.1)\n",
    "# toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.9)\n",
    "\n",
    "# toolbox.register(\"mate\", tools.cxUniform, indpb=0.50)\n",
    "# toolbox.register(\"mutate\", tools.mutUniformInt, low=BOUND_LOW, up=BOUND_UP, indpb=0.50)\n",
    "\n",
    "def checkBounds(min, max):\n",
    "    def decorator(func):\n",
    "        def wrappper(*args, **kargs):\n",
    "            offspring = func(*args, **kargs)\n",
    "            for child in offspring:\n",
    "                for i in range(len(child)):\n",
    "                    if child[i] > max[i]:\n",
    "                        child[i] = max[i]\n",
    "                    elif child[i] < min[i]:\n",
    "#                         print(min[i],child[i])\n",
    "                        child[i] = min[i]\n",
    "            return offspring\n",
    "        return wrappper\n",
    "    return decorator\n",
    "\n",
    "# Bounds on the design variables\n",
    "toolbox.decorate(\"mate\", checkBounds([217, 26, 0], [278, 44, 3]))\n",
    "toolbox.decorate(\"mutate\", checkBounds([217, 26, 0], [278, 44, 3]))\n",
    "\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "toolbox.pop_size = 200\n",
    "toolbox.max_gen = 30\n",
    "toolbox.mut_prob = 0.2\n",
    "\n",
    "stats = tools.Statistics()\n",
    "stats.register(\"pop\", copy.deepcopy)\n",
    "\n",
    "def run_ea(toolbox, stats=None, verbose=False):\n",
    "    pop = toolbox.population(n=toolbox.pop_size)\n",
    "    pop = toolbox.select(pop, len(pop))\n",
    "    return algorithms.eaMuPlusLambda(pop, toolbox, mu=toolbox.pop_size, \n",
    "                                     lambda_=toolbox.pop_size, \n",
    "                                     cxpb=1-toolbox.mut_prob,\n",
    "                                     mutpb=toolbox.mut_prob, \n",
    "                                     stats=stats, \n",
    "                                     ngen=toolbox.max_gen, \n",
    "                                     verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the multi-objective evolutionary algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 20s\n"
     ]
    }
   ],
   "source": [
    "%time pop, logbook = run_ea(toolbox, stats=stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Pareto Front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "\n",
    "# Adjust your matplotlib script by adding the following lines after import matplotlib\n",
    "matplotlib.use(\"pdf\")\n",
    "# matplotlib.use(\"pgf\")\n",
    "    \n",
    "matplotlib.rcParams.update({\n",
    "        \"pgf.texsystem\": \"pdflatex\",\n",
    "        'font.family': 'serif',\n",
    "        'text.usetex': True,\n",
    "        'pgf.rcfonts': False,\n",
    "    })\n",
    "# add LaTeX on python path\n",
    "user_name = os.getlogin()\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Users/' + user_name + '/AppData/Local/Programs/MiKTeX 2.9/miktex/bin/x64'\n",
    "\n",
    "#===========================     Using LaTeX compatible fonts      =============================== #\n",
    "# use LaTeX fonts in the plot\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the figure\n",
    "fig = plt.figure()\n",
    "    \n",
    "filename = 'Case1_pareto_front_bl_MCS_10000_pf_'\n",
    "labels = ['$1-\\mu_{\\mathrm{\\hat{bl}}}$', '$\\sigma_{\\mathrm{\\hat{bl}}}$']\n",
    "\n",
    "# Optimization results\n",
    "front = np.array([ind.fitness.values for ind in pop])\n",
    "x1, y1 = front[:,0], front[:,1]\n",
    "\n",
    "plt.scatter(x1, y1, label='Pareto front',  marker='x', color='red', alpha=0.8)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(r'{}'.format(labels[0]), fontsize=16)\n",
    "plt.ylabel(r'{}'.format(labels[1]), fontsize=16)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.legend(fontsize=15) # using a size in points\n",
    "plt.ylim(bottom=0)  # adjust the bottom leaving top unchanged\n",
    "plt.xlim(left=0.1)\n",
    "# plt.show()\n",
    "\n",
    "# save as PDF\n",
    "fig.savefig(\"{}.pdf\".format(filename), bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Monte Carlo Simulations\n",
    "Plot MCS results with Pareto front obtained from the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# number of MC iterations\n",
    "N = 10000\n",
    "\n",
    "# lower and upper bounds for design variables\n",
    "x_l, x_u = [217, 26, 0], [278, 44, 3]\n",
    "\n",
    "obj = []\n",
    "for itr in range(0,N):\n",
    "    \n",
    "    # design variables\n",
    "    dv1, dv2, dv3 = random.uniform(x_l[0], x_u[0]), random.uniform(x_l[1], x_u[1]), random.uniform(x_l[2], x_u[2])\n",
    "    dv = [dv1,dv2,dv3]\n",
    "    \n",
    "#     print(dv)\n",
    "    \n",
    "    # run MC simulation for each dv combination\n",
    "    line_width = 0.8 # in mm\n",
    "        \n",
    "    if dv[2] <= 1:\n",
    "        l_h = 0.42\n",
    "    elif dv[2] <= 2:\n",
    "        l_h = 0.6\n",
    "    elif dv[2] <= 3:\n",
    "        l_h = 0.7    \n",
    "    \n",
    "    # CONSTRAINT\n",
    "    if dv[1] * line_width * l_h <= 24:\n",
    "        obj1, obj2 = evaluate(dv)\n",
    "        \n",
    "        # append objective results\n",
    "        obj.append([obj1,obj2])\n",
    "    \n",
    "    \n",
    "# print(obj)\n",
    "\n",
    "x_obj1, y_obj2 = [row[0] for row in obj], [row[1] for row in obj]\n",
    "\n",
    "# # row: number of lines, col.: dimension of the plot (e.g., (1,2) -> 1 line with x and y values)\n",
    "# num_lines = 1\n",
    "# dim_plot = 2\n",
    "\n",
    "# # initialize array with size number of lines\n",
    "# data_mc = np.full((num_lines,dim_plot), None)\n",
    "# data_mc[0] = [x_bl,y_th]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Pareto Front with MCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the figure\n",
    "fig = plt.figure()\n",
    "    \n",
    "filename = 'Case1_pareto_front_bl_MCS_10000_'\n",
    "labels = ['$1-\\mu_{\\mathrm{\\hat{bl}}}$', '$\\sigma_{\\mathrm{\\hat{bl}}}$']\n",
    "\n",
    "plt.scatter(x_obj1, y_obj2, label='MCS', alpha=0.2)\n",
    "plt.scatter(x1, y1, label='Pareto front',  marker='x', color='red', alpha=0.8)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(r'{}'.format(labels[0]), fontsize=16)\n",
    "plt.ylabel(r'{}'.format(labels[1]), fontsize=16)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.legend(fontsize=15) # using a size in points\n",
    "plt.ylim(bottom=0)  # adjust the bottom leaving top unchanged\n",
    "plt.xlim(left=0.1)\n",
    "# plt.show()\n",
    "\n",
    "# save as PDF\n",
    "fig.savefig(\"{}.pdf\".format(filename), bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### import file from another folder ###\n",
    "# import sys\n",
    "# # insert at 1, 0 is the script path (or '' in REPL)\n",
    "# sys.path.insert(1, '../Python-Save-Plots')\n",
    "# import save_plots as sP\n",
    "# # import SaveFigAsPDF_PGF as sF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# front = np.array([ind.fitness.values for ind in pop])\n",
    "# # plt.scatter(front[:,0], front[:,1], c=\"b\")\n",
    "# # plt.axis(\"tight\")\n",
    "# # plt.xlabel('$f_1()$')\n",
    "# # plt.ylabel('$f_2()$')\n",
    "# # plt.show()\n",
    "\n",
    "# # Save plots\n",
    "# # legends = ['Train', 'Test']\n",
    "\n",
    "\n",
    "# filename = 'Case1_pareto_front_BL_deneme6'\n",
    "# labels = ['$1-\\mu_{\\mathrm{\\hat{bl}}}$', '$\\sigma_{\\mathrm{\\hat{bl}}}$']\n",
    "\n",
    "# x1, y1 = front[:,0], front[:,1]\n",
    "\n",
    "# # row: number of lines, col.: dimension of the plot (e.g., (1,2) -> 1 line with x and y values)\n",
    "# num_lines = 1\n",
    "# dim_plot = 2\n",
    "\n",
    "# # initialize array with size number of lines\n",
    "# data = np.full((num_lines,dim_plot), None)\n",
    "# data[0] = [x1,y1]\n",
    "\n",
    "# sP.run_subplot(data, labels, filename, plot_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fronts = np.array([[ind,ind.fitness.values] for ind in pop])\n",
    "p_fronts[np.argsort(p_fronts[:,1])] # sorted pop\n",
    "# p_fronts[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fronts = [tools.sortLogNondominated(pop, k=len(pop), first_front_only=True) for pop in logbook.select('pop')]\n",
    "fronts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypervolume computation\n",
    "\n",
    "Sort the best individuals in each local Pareto optimal sets and add a vector (2D; each dimension for each objectives respectively) to obtain the reference point (nadir), worst case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fronts = [tools.sortLogNondominated(pop, k=len(pop), first_front_only=True) for pop in logbook.select('pop')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reference point\n",
    "# # max. obj1 & min. obj2\n",
    "# # reference = np.max([np.max([ind.fitness.values for ind in front], axis=0) for front in fronts], axis=0) + [-0.3, 0.1]\n",
    "# # min. obj1 & min. obj2\n",
    "# reference = np.max([np.max([ind.fitness.values for ind in front], axis=0) for front in fronts], axis=0) + [0.3, 0.1, 0.3, 0.1]\n",
    "# print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import deap.benchmarks.tools as bt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and plot hypervolume indicator wrt. number of generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import matplotlib.pyplot as plt\n",
    "# # %matplotlib inline\n",
    "# # %config InlineBackend.figure_format = 'retina'\n",
    "# # plt.rc('text', usetex=True)\n",
    "\n",
    "# hypervols = [bt.hypervolume(front, reference) for front in fronts]\n",
    "\n",
    "# # plt.figure(figsize=(7, 4))\n",
    "# # plt.plot(hypervols)\n",
    "# # plt.xlabel('Generations')\n",
    "# # plt.ylabel('Hypervolume');\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "# # Save plots\n",
    "# # legends = ['Train', 'Test']\n",
    "# # filename = 'Hypervolume_vs_generations_bl'\n",
    "# # filename = 'Hypervolume_vs_generations_th'\n",
    "# # filename = 'Hypervolume_vs_generations_bl_th'\n",
    "# filename = 'Hypervolume_vs_generations_bl_th_4obj'\n",
    "# labels = ['Generations', 'Hypervolume']\n",
    "# # x1, y1 = range(1,len(hypervols)+1), hypervols\n",
    "# x1 = hypervols\n",
    "\n",
    "# # row: number of lines, col.: dimension of the plot (e.g., (1,2) -> 1 line with x and y values)\n",
    "# num_lines = 1\n",
    "# dim_plot = 1\n",
    "\n",
    "# # initialize array with size number of lines\n",
    "# data = np.full((num_lines,dim_plot), None)\n",
    "\n",
    "# data[0] = [x1]\n",
    "\n",
    "# sP.run_subplot(data, labels, filename, plot_type=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the pareto front individuals wrt. obj1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Animation\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "# plt.rc('text', usetex=True)\n",
    "# plt.rc('font', family='serif')\n",
    "# #     plt.rcParams['text.latex.preamble'] = '\\\\usepackage{libertine}\\n\\\\usepackage[utf8]{inputenc}'\n",
    "\n",
    "# import seaborn\n",
    "# seaborn.set(style='whitegrid')\n",
    "# seaborn.set_context('notebook')\n",
    "# import pandas as pd\n",
    "\n",
    "# from matplotlib import animation\n",
    "# from IPython.display import HTML\n",
    "\n",
    "# def animate(frame_index, logbook):\n",
    "#     'Updates all plots to match frame _i_ of the animation.'\n",
    "#     print(\"Frame Index: \", frame_index)\n",
    "#     ax.clear()\n",
    "#     plot_colors = seaborn.color_palette(\"Set1\", n_colors=10)\n",
    "    \n",
    "#     # get the Pareto fronts in the population (pop).\n",
    "#     fronts = tools.emo.sortLogNondominated(logbook.select('pop')[frame_index],\n",
    "#                                            len(logbook.select('pop')[frame_index]));\n",
    "#     for i, inds in enumerate(fronts):\n",
    "#         par = [toolbox.evaluate(ind) for ind in inds]\n",
    "#         df = pd.DataFrame(par)\n",
    "#         df.plot(ax=ax, kind='scatter', label='Front ' + str(i + 1),\n",
    "#                 x=df.columns[0], y=df.columns[1], alpha=0.47,\n",
    "#                 color=plot_colors[i % len(plot_colors)])\n",
    "\n",
    "#     ax.set_title('$t=$' + str(frame_index))\n",
    "# #     ax.set_xlabel('$1-\\mu_{\\mathrm{\\hat{bl}}}$')\n",
    "# #     ax.set_ylabel('$\\sigma_{\\mathrm{\\hat{bl}}}$')\n",
    "# #     ax.set_xlabel('$\\mu_{\\mathrm{th}}$')\n",
    "# #     ax.set_ylabel('$\\sigma_{\\mathrm{th}}$')\n",
    "#     ax.set_xlabel('$1-\\mu_{\\mathrm{\\hat{bl}}}$')\n",
    "#     ax.set_ylabel('$\\mu_{\\mathrm{th}}$')\n",
    "\n",
    "#     return []\n",
    "\n",
    "# fig = plt.figure(figsize=(6,4))\n",
    "# ax = fig.gca()\n",
    "\n",
    "# anim = animation.FuncAnimation(fig, lambda i: animate(i, logbook),\n",
    "#                                    frames=len(logbook), interval=20,\n",
    "#                                    blit=True)\n",
    "# plt.close()\n",
    "# HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get pareto front populations' design variables and objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_fronts = np.array([[ind,ind.fitness.values] for ind in pop])\n",
    "# # p_fronts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack design variables and objectives and convert the array to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # design variables\n",
    "# dv = p_fronts[:,0]\n",
    "\n",
    "# # objectives\n",
    "# obj = p_fronts[:,1]\n",
    "# # obj = np.array([pop for pop in obj])\n",
    "\n",
    "# obj = np.array([[pop[ob]] for ob in range(len(pop[0])+1) for pop in obj])\n",
    "# obj = obj.reshape(4,toolbox.pop_size).T # 4 objectives, each objectives corresponds to each column, rows are iterations\n",
    "\n",
    "# dv = np.array([[pop[:]] for pop in dv])\n",
    "# dv = dv.reshape(toolbox.pop_size,3) # 3 design variables\n",
    "\n",
    "# dv_obj = np.column_stack((dv,obj))\n",
    "\n",
    "# df = pd.DataFrame(data=dv_obj[:,:],    # values\n",
    "#               columns=[\"$DV_1$\",\"$DV_2$\",\"Height\",\"$Obj_1$\",\"$Obj_2$\",\"$Obj_3$\",\"$Obj_4$\"])  # column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relate the integer design variable 'Height' to real layer heights, i.e., 'Height'==1 means layer height is 0.42 mm and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['$DV_3$'] = 0.42\n",
    "# df.loc[df['Height'] == 2,'$DV_3$'] = 0.6\n",
    "# df.loc[df['Height'] == 3,'$DV_3$'] = 0.7\n",
    "# df = df.drop(['Height'], axis=1)\n",
    "# cols = list(df.columns.values)\n",
    "# df = df[['$DV_1$', '$DV_2$', '$DV_3$', '$Obj_1$', '$Obj_2$', '$Obj_3$', '$Obj_4$']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color bar of objective 1 (1-average bond length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# fig = px.parallel_coordinates(df, color=\"$Obj_1$\",labels={\"$DV_1$\": \"Temperature\",\n",
    "#                 \"$DV_2$\": \"Speed\", \"$DV_3$\": \"Height\",\n",
    "#                 \"$Obj_1$\": \"Obj<sub>1</sub>\", \"$Obj_2$\": \"Obj<sub>2</sub>\", \"$Obj_3$\": \"Obj<sub>3</sub>\", \"$Obj_4$\": \"Obj<sub>4</sub>\"},\n",
    "#                              color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "#                              color_continuous_midpoint=df[\"$Obj_1$\"].mean())\n",
    "# filename='obj1_parallelplot'\n",
    "# # fig.savefig(\"{}.pdf\".format(filename), bbox_inches='tight', dpi=300)\n",
    "# fig.write_image(\"{}.pdf\".format(filename))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color bar of objective 2 (abs(average part thickness-desired_thickness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# fig = px.parallel_coordinates(df, color=\"$Obj_3$\", range_color=[df[\"$Obj_3$\"].min(),df[\"$Obj_3$\"].max()],labels={\"$DV_1$\": \"Temperature\",\n",
    "#                 \"$DV_2$\": \"Speed\", \"$DV_3$\": \"Height\",\n",
    "#                 \"$Obj_1$\": \"Obj<sub>1</sub>\", \"$Obj_2$\": \"Obj<sub>2</sub>\", \"$Obj_3$\": \"Obj<sub>3</sub>\", \"$Obj_4$\": \"Obj<sub>4</sub>\"},\n",
    "#                              color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "#                              color_continuous_midpoint=df[\"$Obj_3$\"].mean())\n",
    "\n",
    "# fig.update_layout(\n",
    "# #     title=\"Plot Title\",\n",
    "# #     xaxis_title=\"x Axis Title\",\n",
    "# #     yaxis_title=\"y Axis Title\",\n",
    "#     font=dict(\n",
    "#         family=\"serif\",\n",
    "#         size=18,\n",
    "# #         color=\"#7f7f7f\"\n",
    "#     ))\n",
    "    \n",
    "# filename='obj3new_parallelplot'\n",
    "# fig.write_image(\"{}.pdf\".format(filename))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel plot\n",
    "\n",
    "For single objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_fronts = np.array([[ind,ind.fitness.values] for ind in pop])\n",
    "# # p_fronts\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # design variables\n",
    "# dv = p_fronts[:,0]\n",
    "\n",
    "# # objectives\n",
    "# obj = p_fronts[:,1]\n",
    "\n",
    "# # for 2 objective case\n",
    "# # obj = np.array([pop for pop in obj])\n",
    "\n",
    "# # for 4 objective case\n",
    "# obj = np.array([[pop[ob]] for ob in range(len(pop[0])+1) for pop in obj])\n",
    "# obj = obj.reshape(4,toolbox.pop_size).T # 4 objectives, each objectives corresponds to each column, rows are iterations\n",
    "\n",
    "# dv = np.array([[pop[:]] for pop in dv])\n",
    "# dv = dv.reshape(toolbox.pop_size,3) # 3 design variables\n",
    "\n",
    "# dv_obj = np.column_stack((dv,obj))\n",
    "\n",
    "# df = pd.DataFrame(data=dv_obj[:,:],    # values\n",
    "#               columns=[\"$DV_1$\",\"$DV_2$\",\"Height\",\"$Obj_1$\",\"$Obj_2$\",\"$Obj_3$\",\"$Obj_4$\"])  # column names\n",
    "\n",
    "# df['$DV_3$'] = 0.42\n",
    "# df.loc[df['Height'] == 2,'$DV_3$'] = 0.6\n",
    "# df.loc[df['Height'] == 3,'$DV_3$'] = 0.7\n",
    "# df = df.drop(['Height'], axis=1)\n",
    "# cols = list(df.columns.values)\n",
    "# df = df[['$DV_1$', '$DV_2$', '$DV_3$', '$Obj_1$', '$Obj_2$',\"$Obj_3$\",\"$Obj_4$\"]]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# fig = px.parallel_coordinates(df, color=\"$Obj_3$\",labels={\"$DV_1$\": \"Temperature\",\n",
    "#                 \"$DV_2$\": \"Speed\", \"$DV_3$\": \"Height\",\n",
    "#                 \"$Obj_1$\": \"Obj<sub>1</sub>\", \"$Obj_2$\": \"Obj<sub>2</sub>\",\"$Obj_3$\": \"Obj<sub>3</sub>\", \"$Obj_4$\": \"Obj<sub>4</sub>\"},\n",
    "#                              color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "#                              color_continuous_midpoint=df[\"$Obj_1$\"].mean())\n",
    "# # filename='bl_parallelplot'\n",
    "# # fig.write_image(\"{}.pdf\".format(filename))\n",
    "# # fig.show()\n",
    "\n",
    "# # filename='bl_th_parallelplot'\n",
    "# # fig.write_image(\"{}.pdf\".format(filename))\n",
    "# # fig.show()\n",
    "\n",
    "# filename='obj3_parallelplot'\n",
    "# fig.write_image(\"{}.pdf\".format(filename))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
