{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\torch\\serialization.py:420: UserWarning: Couldn't retrieve source code for container of type MC_Dropout_Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#    This file is part of Multi-objective optimization under uncertainty research\n",
    "\n",
    "import array, copy, random\n",
    "# import logging\n",
    "# import random\n",
    "import numpy as np\n",
    "\n",
    "# imports for the BNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle\n",
    "\n",
    "from deap import algorithms, base, creator, tools\n",
    "\n",
    "\n",
    "# load min and max values of the data to denormalize prediction data\n",
    "with open('maxmin.pickle', 'rb') as f:\n",
    "    [max_x, min_x, max_y, min_y] = pickle.load(f)\n",
    "    \n",
    "# load min and max values of the data to denormalize prediction data\n",
    "with open('maxmin_thickness.pickle', 'rb') as f:\n",
    "    [X_max, X_min, Y_max, Y_min] = pickle.load(f)    \n",
    "\n",
    "def normalize_max_min(data, data_max, data_min):\n",
    "    return (data-data_min) / (data_max-data_min)\n",
    "\n",
    "def denormalize_max_min(data, data_max, data_min):\n",
    "    return data * (data_max-data_min) + data_min\n",
    "\n",
    "class KerasDropoutPrediction(object):\n",
    "    def __init__(self,model):\n",
    "        self.f = K.function(\n",
    "                [model.layers[0].input, \n",
    "                 K.learning_phase()],\n",
    "                [model.layers[-1].output])\n",
    "        \n",
    "    def predict(self, x, n_iter=10):\n",
    "        result = []\n",
    "        for _ in range(n_iter):\n",
    "            result.append(self.f([x, 1]))\n",
    "        result = np.array(result).reshape(n_iter,len(x)).T\n",
    "        return result\n",
    "    \n",
    "class MC_Dropout_Model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_units, drop_prob):\n",
    "        super(MC_Dropout_Model, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        # network with two hidden and one output layer\n",
    "        self.layer1 = nn.Linear(input_dim, num_units)\n",
    "        self.layer2 = nn.Linear(num_units, num_units)\n",
    "        self.layer3 = nn.Linear(num_units, 2 * output_dim)\n",
    "\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = F.dropout(x, p=self.drop_prob, training=True)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = self.activation(x)\n",
    "        x = F.dropout(x, p=self.drop_prob, training=True)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "# load BL model BNN and evaluate objectives\n",
    "model_BL = torch.load('BNN_BLmodel.pt')\n",
    "\n",
    "# load the thickness model\n",
    "model_thickness = keras.models.load_model('MCdropout_model_thickness.h5', compile=False)\n",
    "\n",
    "# predict with dropout\n",
    "kdp = KerasDropoutPrediction(model_thickness)\n",
    "\n",
    "\n",
    "def evaluate(vars):\n",
    "    \n",
    "#     # load BL model BNN\n",
    "#     BL_model = torch.load('BNN_BLmodel.pt')\n",
    "\n",
    "    # Minimize(abs(pred_mean â€“ target))\n",
    "    target  = 4.2 # desired part thickness in mm\n",
    "\n",
    "    # number of total layers = (maximum part height)/(height of a layer), i.e., 4.2 / (layer height)\n",
    "    if vars[2] == 1:\n",
    "        height = 0.42\n",
    "    elif vars[2] == 2:\n",
    "        height = 0.6\n",
    "    elif vars[2] == 3:\n",
    "        height = 0.7\n",
    "\n",
    "    # print(vars)\n",
    "    num_layers = np.int(target / height); # number of layers\n",
    "\n",
    "    num_interfaces = 14     # number of interfaces per layer\n",
    "    width = 0.8             # filament width in mm\n",
    "\n",
    "    ycoord = 0.5 * height  # 0.5*height of a layer in mm\n",
    "    iki_y = ycoord * 2\n",
    "    \n",
    "    # Create an input array to predict overall part thickness\n",
    "    inp_BL = [] # input to BNN to make predictions\n",
    "    \n",
    "    # store inputs for GP(model disrepancy at each interface)\n",
    "    for jj in range(1, num_layers + 1):\n",
    "        for ii in range(1, num_interfaces + 1):\n",
    "            # use x & y coordinates of vertical bonds as training data for the GP\n",
    "            # Inp =[ Temperature, speed, height, x, y ]\n",
    "            inp_BL.append([vars[0], vars[1], height, ii * width, ycoord + (jj - 1) * iki_y])\n",
    "\n",
    "    # Convert built Python lists to a Numpy array.\n",
    "    inp_BL = np.array(inp_BL, dtype='float32')\n",
    "\n",
    "    # normalize data\n",
    "    inp_BL = normalize_max_min(inp_BL, max_x, min_x)\n",
    "\n",
    "    x_pred = torch.tensor(inp_BL)  # convert to torch tensor\n",
    "\n",
    "    samples = []\n",
    "    noises = []\n",
    "    for i in range(50):\n",
    "        preds = model_BL.forward(x_pred).cpu().data.numpy()\n",
    "        samples.append(denormalize_max_min(preds[:, 0], max_y, min_y))\n",
    "        noises.append(denormalize_max_min(np.exp(preds[:, 1]), max_y, min_y))\n",
    "\n",
    "    samples, noises = np.array(samples),  np.array(noises)\n",
    "    means = (samples.mean(axis=0)).reshape(-1)\n",
    "\n",
    "    aleatoric = (noises ** 2).mean(axis=0) ** 0.5\n",
    "    epistemic = (samples.var(axis=0) ** 0.5).reshape(-1)\n",
    "    total_unc = (aleatoric ** 2 + epistemic ** 2) ** 0.5\n",
    "\n",
    "\n",
    "    # Dimensionless BL: non-dimensionalize the BL by dividing with the layer height\n",
    "    dimensionless_mean_bl = means.mean()/height\n",
    "    dimensionless_total_unc_bl = total_unc.mean()/height**2\n",
    "\n",
    "    \n",
    "#     # load the thickness model\n",
    "#     model_thickness = keras.models.load_model('MCdropout_model_thickness.h5', compile=False)\n",
    "\n",
    "#     # predict with dropout\n",
    "#     kdp = KerasDropoutPrediction(model_thickness)\n",
    "\n",
    "    x_pos = 7 # mm\n",
    "    num_iter = (10.5-1.5)/0.01 + 1\n",
    "        \n",
    "     # Create an input array to predict overall part thickness\n",
    "    inp_thickness = []\n",
    "    \n",
    "    # store inputs for GP(model disrepancy at each interface)\n",
    "    for jj in range(5):\n",
    "\n",
    "        y_pos = 1.5 # mm\n",
    "\n",
    "        for ii in range(int(num_iter)):\n",
    "            # use x & y coordinates of vertical bonds as training data for the GP\n",
    "            # Inp =[ Temperature, speed, height, x, y]\n",
    "            inp_thickness.append([vars[0], vars[1], height, x_pos, y_pos])\n",
    "            \n",
    "            y_pos += 0.01 # increment y position 0.01 mm\n",
    "\n",
    "        x_pos += 5 # x coordinate  \n",
    "    \n",
    "    # Convert built Python lists to a Numpy array.\n",
    "    inp_thickness = np.array(inp_thickness, dtype='float32')\n",
    "\n",
    "    # normalize data\n",
    "    inp_thickness = normalize_max_min(inp_thickness, X_max, X_min)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_do = kdp.predict(inp_thickness,n_iter=100)\n",
    "    y_pred_do_org = denormalize_max_min(y_pred_do, Y_max, Y_min)\n",
    "    y_pred_do_org_mean = y_pred_do_org.mean(axis=1).reshape(-1, 1)\n",
    "    y_pred_do_org_std = y_pred_do_org.std(axis=1).reshape(-1, 1)\n",
    "    \n",
    "    # Predicted mean and std part thicknesses\n",
    "    mean_part_thickness = y_pred_do_org_mean.mean()\n",
    "    std_part_thickness = ((y_pred_do_org_std**2).mean())**0.5\n",
    "    \n",
    "    return 1-dimensionless_mean_bl, abs(mean_part_thickness-target)\n",
    "\n",
    "\n",
    "\n",
    "# The constraint is:\n",
    "# (Nozzle velocity) x (line width) x (layer thickness)  less than/ equal to 24 mm/s3\n",
    "def feasible(individual):\n",
    "    \"\"\"Feasability function for the individual. Returns True if feasible False\n",
    "    otherwise.\"\"\"\n",
    "    \n",
    "    line_width = 0.8 # in mm\n",
    "    \n",
    "    # layer height in mm\n",
    "    if individual[2] == 1:\n",
    "        height = 0.42\n",
    "    elif individual[2] == 2:\n",
    "        height = 0.6\n",
    "    elif individual[2] == 3:\n",
    "        height = 0.7\n",
    "        \n",
    "    if individual[1] * line_width * height <= 24:\n",
    "#         print(individual,'true')\n",
    "        return True\n",
    "#     print(individual,'false')\n",
    "    return False\n",
    "\n",
    "IND_SIZE = 3\n",
    "N_CYCLES = 1\n",
    "BOUND_LOW, BOUND_UP = [217, 26, 1], [278, 44, 3]\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0))\n",
    "creator.create(\"Individual\", array.array, typecode='d', fitness=creator.FitnessMin, n=IND_SIZE)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Attribute generator\n",
    "toolbox.register(\"attr_temperature\", random.randint, 217, 278)\n",
    "toolbox.register(\"attr_speed\", random.randint, 26, 44)\n",
    "toolbox.register(\"attr_layer\", random.randint, 1, 3)\n",
    "\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_temperature,toolbox.attr_speed,toolbox.attr_layer), n=N_CYCLES)\n",
    "\n",
    "# Structure initializers\n",
    "# toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, 3)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# load BL model BNN and evaluate objectives\n",
    "# toolbox.model1 = torch.load('BNN_BLmodel.pt')\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "# # load the thickness model\n",
    "# model_thickness = keras.models.load_model('MCdropout_model_thickness.h5', compile=False)\n",
    "\n",
    "# # predict with dropout\n",
    "# toolbox.model2 = KerasDropoutPrediction(model_thickness)\n",
    "\n",
    "# A penality function can be added to any evaluation function using the DeltaPenality decorator provided in the tools module.\n",
    "# Delta = [0,1] worst cases\n",
    "toolbox.decorate(\"evaluate\", tools.DeltaPenality(feasible, [1,1]))\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxUniform, indpb=0.50)\n",
    "toolbox.register(\"mutate\", tools.mutUniformInt, low=BOUND_LOW, up=BOUND_UP, indpb=0.50)\n",
    "\n",
    "def checkBounds(min, max):\n",
    "    def decorator(func):\n",
    "        def wrappper(*args, **kargs):\n",
    "            offspring = func(*args, **kargs)\n",
    "            for child in offspring:\n",
    "                for i in range(len(child)):\n",
    "                    if child[i] > max[i]:\n",
    "#                         print(child[i])\n",
    "                        child[i] = max[i]\n",
    "                    elif child[i] < min[i]:\n",
    "#                         print(child[i])\n",
    "                        child[i] = min[i]\n",
    "            return offspring\n",
    "        return wrappper\n",
    "    return decorator\n",
    "\n",
    "# Bounds on the design variables\n",
    "toolbox.decorate(\"mate\", checkBounds([217, 26, 1], [278, 44, 3]))\n",
    "toolbox.decorate(\"mutate\", checkBounds([217, 26, 1], [278, 44, 3]))\n",
    "\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "# ref_points = tools.uniform_reference_points(nobj=2, p=12)\n",
    "# toolbox.register(\"select\", tools.selNSGA3WithMemory(ref_points))\n",
    "\n",
    "# toolbox.pop_size = 100\n",
    "# toolbox.max_gen = 10\n",
    "toolbox.mut_prob = 0.2\n",
    "\n",
    "# def main(toolbox):\n",
    "#     random.seed(64)\n",
    "\n",
    "#     pop = toolbox.population(n=toolbox.pop_size)\n",
    "#     hof = tools.ParetoFront()\n",
    "#     stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "#     stats.register(\"avg\", np.mean, axis=0)\n",
    "#     stats.register(\"std\", np.std, axis=0)\n",
    "#     stats.register(\"min\", np.min, axis=0)\n",
    "#     stats.register(\"max\", np.max, axis=0)\n",
    "\n",
    "#     algorithms.eaMuPlusLambda(pop, toolbox, mu=toolbox.pop_size, lambda_=toolbox.pop_size,\n",
    "#                               cxpb=1-toolbox.mut_prob, mutpb=toolbox.mut_prob, ngen=toolbox.max_gen,\n",
    "#                               stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "#     return pop, stats, hof\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     pop, stats, hof = main(toolbox)\n",
    "\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import numpy\n",
    "\n",
    "#     front = numpy.array([ind.fitness.values for ind in pop])\n",
    "#     plt.scatter(front[:,0], front[:,1], c=\"b\")\n",
    "#     plt.axis(\"tight\")\n",
    "#     plt.xlabel(\"Dimensionless Mean Bond Length\")\n",
    "#     plt.ylabel(\"Absolute Error of Mean Part Thickness\")\n",
    "#     plt.show()\n",
    "    \n",
    "# stats = tools.Statistics()\n",
    "# stats.register(\"pop\", copy.deepcopy)\n",
    "\n",
    "def run_ea(toolbox, stats=None, verbose=False):\n",
    "    pop = toolbox.population(n=toolbox.pop_size)\n",
    "    pop = toolbox.select(pop, len(pop))\n",
    "    return algorithms.eaMuPlusLambda(pop, toolbox, mu=toolbox.pop_size, \n",
    "                                     lambda_=toolbox.pop_size, \n",
    "                                     cxpb=1-toolbox.mut_prob,\n",
    "                                     mutpb=toolbox.mut_prob, \n",
    "                                     stats=stats, \n",
    "                                     ngen=toolbox.max_gen, \n",
    "                                     verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### import file from another folder ###\n",
    "# import sys\n",
    "# # insert at 1, 0 is the script path (or '' in REPL)\n",
    "# sys.path.insert(1, '../Python-Save-Plots')\n",
    "# import save_plots as sP\n",
    "# # import SaveFigAsPDF_PGF as sF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# front = np.array([ind.fitness.values for ind in pop])\n",
    "    \n",
    "# x1, y1 = front[:,0], front[:,1]\n",
    "\n",
    "# # row: number of lines, col.: dimension of the plot (e.g., (1,2) -> 1 line with x and y values)\n",
    "# num_lines = 1\n",
    "# dim_plot = 2\n",
    "\n",
    "# # initialize array with size number of lines\n",
    "# data = np.full((num_lines,dim_plot), None)\n",
    "# data[0] = [x1,y1]\n",
    "\n",
    "# sP.run_subplot(data, labels, filename, plot_type=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design of experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the optimal optimization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"$n_\\mathrm{{pop}}={0};\\ n_\\mathrm{{gen}}={1}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_sizes = (10,50,100)       # population size\n",
    "total_evals = 100          # total num. of evaluations\n",
    "number_of_runs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicate this toolbox instance\n",
    "toolboxes=list([copy.deepcopy(toolbox) for _ in range(len(pop_sizes))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the population sizes in the elements of toolboxes\n",
    "for pop_size, toolbox in zip(pop_sizes, toolboxes):\n",
    "    toolbox.pop_size = pop_size\n",
    "    toolbox.max_gen = total_evals // pop_size\n",
    "    toolbox.experiment_name = experiment_name.format(toolbox.pop_size, toolbox.max_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of run: 0\n",
      "number of run: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1312, in time\n",
      "    exec(code, glob, local_ns)\n",
      "  File \"<timed exec>\", line 6, in <module>\n",
      "  File \"<timed exec>\", line 329, in run_ea\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\deap\\algorithms.py\", line 321, in eaMuPlusLambda\n",
      "    for ind, fit in zip(invalid_ind, fitnesses):\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\deap\\tools\\constraint.py\", line 53, in wrapper\n",
      "    return func(individual, *args, **kwargs)\n",
      "  File \"<timed exec>\", line 186, in evaluate\n",
      "  File \"<timed exec>\", line 45, in predict\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3076, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1439, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\berkc\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {toolbox.experiment_name:[] for toolbox in toolboxes}\n",
    "\n",
    "for _ in range(number_of_runs):\n",
    "    print('number of run:', _)\n",
    "    for toolbox in toolboxes:\n",
    "        result, _ = run_ea(toolbox)\n",
    "        local_pareto_set = tools.emo.sortLogNondominated(result, len(result), first_front_only=True)\n",
    "        results[toolbox.experiment_name].append(local_pareto_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0f112bc49057>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    409\u001b[0m             )\n\u001b[0;32m    410\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         ]\n\u001b[1;32m--> 257\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\Clone_Research_AM_2020\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "res = pd.DataFrame(results)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rc('text', usetex=True)\n",
    "\n",
    "a = res.applymap(lambda pop: [toolbox.evaluate(ind) for ind in pop])\n",
    "fig = plt.figure(figsize=(11,3))\n",
    "for i, col in enumerate(a.columns):\n",
    "    plt.subplot(1, len(a.columns), i+1)\n",
    "    for pop in a[col]:\n",
    "        x = pd.DataFrame(data=pop)\n",
    "        plt.scatter(x[0], x[1], marker='.', alpha=0.5)\n",
    "    plt.title(col)\n",
    "    plt.xlabel('$1-\\mu_{\\mathrm{\\hat{bl}}}$')\n",
    "    plt.ylabel('$\\mu_{\\mathrm{\\th}}$')\n",
    "    \n",
    "filename = 'Pareto_front_exp_design'\n",
    "fig.savefig(\"{}.pdf\".format(filename), bbox_inches='tight', dpi=300)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypervolume computation\n",
    "\n",
    "Sort the best individuals in each local Pareto optimal sets and add a vector (2D; each dimension for each objectives respectively) to obtain the reference point (nadir), worst case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deap.benchmarks.tools as bt\n",
    "\n",
    "# Reference point\n",
    "# reference = np.max([np.max([ind.fitness.values for ind in front], axis=0) for front in fronts], axis=0) + [-0.4, 0.1]\n",
    "\n",
    "def calculate_reference(results, epsilon=[0.3,0.1]):\n",
    "    alldata = np.concatenate(np.concatenate(results.values))\n",
    "    obj_vals = [toolbox.evaluate(ind) for ind in alldata]\n",
    "    return np.max(obj_vals, axis=0) + epsilon\n",
    "\n",
    "reference = calculate_reference(res)\n",
    "\n",
    "hypervols = res.applymap(lambda pop: bt.hypervolume(pop, reference))\n",
    "hypervols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypervols.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "\n",
    "fig = plt.figure()\n",
    "# plt.subplot(121, title='Violin plots of NSGA-II with $P_{\\mathrm{mut}}$')\n",
    "# seaborn.violinplot(data=hypervols, palette='Set2')\n",
    "# plt.ylabel('Hypervolume'); plt.xlabel('Configuration')\n",
    "# plt.subplot(title='Box plots of NSGA-II with $P_{\\mathrm{mut}}$')\n",
    "seaborn.boxplot(data=hypervols, palette='Set2')\n",
    "plt.ylabel('Hypervolume'); plt.xlabel('Parameter set');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Hypervolume_exp_design'\n",
    "fig.savefig(\"{}.pdf\".format(filename), bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Clone_Research_AM_2020",
   "language": "python",
   "name": "clone_research_am_2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
